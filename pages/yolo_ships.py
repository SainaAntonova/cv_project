import streamlit as st
import cv2
import numpy as np 
from PIL import Image
from io import BytesIO
import requests
from ultralytics import YOLO
import os
import torch
from torchvision import transforms

st.image("https://blogs.mathworks.com/deep-learning/files/2022/02/Cover.png", use_column_width=True)
st.markdown("""
    <style>
        .title {
            font-family: 'Arial Black', sans-serif;
            font-size: 36px;
            color: #1E90FF;
            text-align: center;
            margin-bottom: 30px;
        }
        .sidebar .sidebar-content {
            background-image: linear-gradient(#2e7bcf,#2e7bcf);
            color: white;
        }
        .stButton>button {
            color: white;
            background: linear-gradient(to right, #1fa2ff, #12d8fa, #a6ffcb);
        }
        .uploaded-image {
            border: 5px solid #1E90FF;
            border-radius: 10px;
            margin-bottom: 15px;
        }
    </style>
    """, unsafe_allow_html=True)

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
st.markdown('<h1 class="title">‚õ¥Ô∏èüì°üì∑ YOLOv8üõ∞Ô∏èüõ≥Ô∏è</h1>', unsafe_allow_html=True)
st.write("""
         
    –ú–æ–¥–µ–ª—å YOLOv8 –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ [KAGGLE - Ships/Vessels in Aerial Images](https://www.kaggle.com/datasets/siddharthkumarsah/ships-in-aerial-images/code)
    """)

with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏"):
    st.write('## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏')
    st.write('- –ß–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤: 1 - –∫–æ—Ä–∞–±–ª—å')
    st.write('- –û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏: 13 435 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π')
    
    st.image('notebooks/model/yolo_runs/detect/train2/val_batch1_labels.jpg')
with st.expander("–ú–µ—Ç—Ä–∏–∫–∏"):
    st.write('## –ú–µ—Ç—Ä–∏–∫–∏:')
    st.write('  - mAP50: 0.5683,\n  - mAP50-95: 0.30734')
    st.image('notebooks/model/yolo_runs/detect/train2/results.png')
    st.write('  - –ì—Ä–∞—Ñ–∏–∫ Percision-Recall –∫—Ä–∏–≤–æ–π')
    st.image('notebooks/model/yolo_runs/detect/train2/PR_curve.png')
    st.write('  - Confusion Matrix')
    st.image('notebooks/model/yolo_runs/detect/train2/confusion_matrix_normalized.png')
    st.write('F1-–∫—Ä–∏–≤–∞—è')
    st.image('notebooks/model/yolo_runs/detect/train2/F1_curve.png')



with st.sidebar:
    st.title("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    upload_type = st.radio(
        label="–ö–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É?",
        options=(("–ò–∑ —Ñ–∞–π–ª–∞", "–ò–∑ URL", "–ò–∑ –≤–µ–±–∫–∞–º–µ—Ä—ã")),
    )

    image = None
    if upload_type == "–ò–∑ —Ñ–∞–π–ª–∞":
        files = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑ –ø–∞–ø–∫–∏ –∏–ª–∏ –ø–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Å–≤–æ–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏", type=["jpg", "jpeg", "png"], accept_multiple_files=True
        )
        if files:
            image = [file.getvalue() for file in files]

    if upload_type == "–ò–∑ URL":
        url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL")
        if url:
            image = [requests.get(url).content]

    if upload_type == "–ò–∑ –≤–µ–±–∫–∞–º–µ—Ä—ã":
        camera = st.camera_input("### üßÄüßÄüßÄ–°—ã—ã—Ä!üßÄüßÄüßÄ")
        if camera:
            image = [camera.getvalue()]

st.write("## –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ & –ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏")
if image:
    st.write("üéâ –í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç!")
    # st.image(image, width=200)
else:
    
    st.warning("üëà –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    st.stop()



@st.cache_resource()
# YOLOv8
def load_model(weights_path='notebooks/model/yolo_runs/detect/train2/weights/best.pt'):
    model = YOLO(weights_path)
    return model

# # YOLOv5
# def load_model(weights_path='notebooks/model/yolo_runs/train/exp/weights/best.pt'):
#     model = YOLO(weights_path)
#     return model


# #–ø—Ä–æ–±–Ω—ã–π –∑–∞–ø—É—Å–∫
# def load_model():
#     model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # –ó–∞–≥—Ä—É–∑–∫–∞ YOLOv5s
#     return model

model = load_model()

def predict(img):
    img = np.array(img)
    result = model(img)
    return result


# image = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ—ë –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —É–≤–∏–¥–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–æ—Ä–∞–±–ª–µ–π!", type=["jpg", "jpeg", "png"])

def load_image(image_file):
    if isinstance(image_file, str):
        response = requests.get(image_file)
        image = Image.open(BytesIO(response.content))
    else:
        image = Image.open(image_file)
    return image



if image:
    images = [Image.open(BytesIO(image)) for image in image]
    predictions = [predict(image) for image in images]
    # predictions = [predict(np.array(image)) for image in images]
    
    for image, prediction in zip(images, predictions):
        col1, col2= st.columns(2)
        with col1:
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            st.image(image, caption='–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
        with col2:
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –æ–±—ä–µ–∫—Ç–æ–≤
            detected_image = prediction[0].plot()  # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –æ–±—ä–µ–∫—Ç–æ–≤
            st.image(detected_image, caption='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã', use_column_width=True)

    st.image("https://media0.giphy.com/media/9xnNG7EN2h822ithtT/giphy.gif?cid=6c09b952jkeqsu1vzio1sr6gr67m941155ubajei5yltumvk&ep=v1_gifs_search&rid=giphy.gif&ct=g", use_column_width=True)