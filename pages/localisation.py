import streamlit as st
from PIL import Image
import torch
from torch import nn
from torchvision.models import ResNet18_Weights, resnet18
from notebooks.model.loc_model.preprocessing import preprocess
import cv2
import numpy as np

class Classifier(nn.Module):
    def __init__(self):
        super().__init__()

        self.feature_extractor = resnet18(weights=ResNet18_Weights.DEFAULT)
        self.feature_extractor = nn.Sequential(*list(self.feature_extractor.children())[:-2])
        for param in self.feature_extractor.parameters():
            param.requires_grad = False

        self.clf = nn.Sequential(
            nn.Linear(512 * 8 * 8, 256),
            nn.Tanh(),
            nn.Linear(256, 3)
        )

        self.box = nn.Sequential(
            nn.Linear(512 * 8 * 8, 512),
            nn.LeakyReLU(),
            nn.Dropout(),
            nn.Linear(512, 256),
            nn.LeakyReLU(),
            nn.Dropout(),
            nn.Linear(256, 128),
            nn.LeakyReLU(),
            nn.Linear(128, 4),
            nn.Sigmoid()
        )

    def forward(self, img):
        embedding = self.feature_extractor(img)
        logits = self.clf(torch.flatten(embedding, 1))
        box_coords = self.box(torch.flatten(embedding, 1))
        return logits, box_coords

@st.cache_data
def load_model():
    model = Classifier()
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    url = 'https://drive.google.com/file/d/1Zv6ojBq4jFyXE0AKVvYb5RifEmQzRBVN/view'
    output = 'best.pth'  # Local filename to save the downloaded model
    gdown.download(url, output, quiet=False)  # Download the model
    checkpoint = torch.load(output) 

    
    # checkpoint = torch.load('notebooks/model/loc_model/best.pth')
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=.9)
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25])

    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    start_epoch = checkpoint['epoch']
    log = checkpoint['log']
    model.eval()
    return model, start_epoch

model, start_epoch = load_model()

st.image("https://previews.123rf.com/images/foodandmore/foodandmore1705/foodandmore170500090/77253581-panoramic-wide-organic-food-background-concept-with-full-frame-pile-of-fresh-vegetables-and-fruits.jpg", use_column_width=True)
st.markdown("""
    <style>
        .title {
            font-family: 'Arial Black', sans-serif;
            font-size: 36px;
            color: #1E90FF;
            text-align: center;
            margin-bottom: 30px;
        }
        .sidebar .sidebar-content {
            background-image: linear-gradient(#2e7bcf,#2e7bcf);
            color: white;
        }
        .stButton>button {
            color: white;
            background: linear-gradient(to right, #1fa2ff, #12d8fa, #a6ffcb);
        }
        .uploaded-image {
            border: 5px solid #1E90FF;
            border-radius: 10px;
            margin-bottom: 15px;
        }
    </style>
    """, unsafe_allow_html=True)

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
st.markdown('<h1 class="title">üì∑ –õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ ResNet-18</h1>', unsafe_allow_html=True)
st.write("""
         –≠—Ç–æ—Ç –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–π –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ ResNet-18.
         –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏ –ª–æ–∫–∞–ª–∏–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, –æ—Ç–æ–±—Ä–∞–∂–∞—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ —Ä–∞–º–∫–∏ –≤–æ–∫—Ä—É–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤.
    """)

with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏"):
    st.write('## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏')
    st.write('- –ß–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤: 3 - –æ–≥—É—Ä–µ—Ü, –±–∞–∫–ª–∞–∂–∞–Ω, –≥—Ä–∏–±')
    st.write('- –û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏: 186 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π')

with st.expander("–ú–µ—Ç—Ä–∏–∫–∏"):
    st.write('## –ú–µ—Ç—Ä–∏–∫–∏:')
    st.write('  - mAP50: ???  - mAP50-95: ???')



with st.sidebar:
    image = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ—é –∫–∞—Ä—Ç–∏–Ω–∫—É', type=['jpg', 'jpeg', 'png'], accept_multiple_files=True)

def predict(model, image, device='cpu'):
    img = preprocess(image)

    # Ensure img is a 4D tensor
    if img.dim() == 3:
        img = img.unsqueeze(0)  # Add batch dimension

    with torch.no_grad():
        img = img.to(device)
        logits, coords = model(img)
        logits = logits.cpu()
        coords = coords.cpu()
    return logits, coords

label_dict = {
            'cucumber' : 0,
            'eggplant' : 1,
            'mushroom' : 2
            }

ix2cls = {v: k for k, v in label_dict.items()}

st.write('## –í–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:')
if image:
    for uploaded_image in image:
        image = Image.open(uploaded_image)
        orig_width, orig_height = image.size
        logits, coords = predict(model, image)
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –±–æ–∫—Å–∞
        coords = coords.squeeze().numpy()
        xmin, ymin, xmax, ymax = coords
        pred_label = logits.argmax(1).item()
        pred_class = ix2cls[pred_label]
        image_np = np.array(image)
        cv2.rectangle(image_np, (int(xmin*orig_width), int(ymin*orig_height)), (int(xmax*orig_width), int(ymax*orig_height)), (255, 0, 0), 1)
        cv2.putText(image_np, pred_class, (int(xmin*orig_width), int(ymin*orig_height)-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        image = Image.fromarray(image_np)
        st.image(image)
        st.write(f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: {start_epoch}')
